{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating random text data for Pandas\n",
    "\n",
    "## Creating random length sentences of random length words using random characters\n",
    "\n",
    "### Background\n",
    "\n",
    "A friend recently asked about transforming data in a Pandas data frame and provided an example of what the target column contains currently (prior to the transformation).\n",
    "\n",
    "After I and a few others made some suggestions, there was also some discussion on performance of the different method of applying the desired transformation.\n",
    "\n",
    "So that we could properly test, I decided to make some test data, and this in itself provided a challenge.\n",
    "\n",
    "Briefly, the column of data contained JSON data with:\n",
    "\n",
    "1. A single-element array\n",
    "2. Containing an Object (actually, more like a set in Python)\n",
    "3. Containing one or more words separated by commas\n",
    "\n",
    "An example (similar to that provided by my friend):\n",
    "\n",
    "`[{These, words, are, contained, by, an, Object, or, set, which, itself, is, contained, by, an, array}]`  \n",
    "`[{The, next, set, of, words, is, like, this}]`\n",
    "\n",
    "As yet, it is not clear whether the data contained the individual words wrapped by double quotes or not, and possibly the data was actually\n",
    "\n",
    "`[{\"These\", \"words\", \"are\", \"contained\", \"by\", \"an\", \"Object\", \"or\", \"set\", \"which\", \"itself\", \"is\", \"contained\", \"by\", \"an\", \"array\"}]`  \n",
    "`[{\"The\", \"next\", \"set\", \"of\", \"words\", \"is\", \"like\", \"this\"}]`\n",
    "\n",
    "Having this example, the challenge is to create a lot of data with a random number of words in each \"sentence\", where each word contains a random number of letters.\n",
    "\n",
    "Just the notion of the word \"random\" implies using `numpy.random` however, none of the methods available in that class can help us directly in our task. For that, we will also need to make use of `itertools` and a not so well known (well, at east to me) method of splitting an array by unequal length intervals using `numpy.split`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import random as rand\n",
    "import numpy as np\n",
    "import itertools as itools\n",
    "#import unicodedata\n",
    "import re\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_RECORDS = 1000000\n",
    "MAX_WORDS_PER_SENTENCE = 20\n",
    "MAX_CHARS_PER_WORD = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a \"template\" (of sorts) for our records.\n",
    "# This template will tell us how many words randomly will be in each record.\n",
    "sentence_templates = rand.randint(low=1, high=MAX_WORDS_PER_SENTENCE+1, size=NUM_RECORDS)\n",
    "\n",
    "# Create another \"template\" which will be a random number of characters for each word.\n",
    "# We know the count of all words across all records by using the sum() method of the numpy array sentence_templates\n",
    "word_templates = rand.randint(low=1, high=MAX_CHARS_PER_WORD+1, size=sentence_templates.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10498244"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's just see how many words we will have in total\n",
    "len(word_templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use itertools to creating a running count of words\n",
    "# For example, if the first 5 sentences (records) had word counts of 7, 3, 4, 8, 2\n",
    "# itertools would return 7, 10, 14, 22, 24\n",
    "# This running count is needed in the numpy.split method later\n",
    "words_iter = list(itools.accumulate(word_templates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's create an array of random characters from A-Z,\n",
    "# having length = the last element of our word iterator.\n",
    "# Similar to the example of 5 above where 24 would be returned as the size.\n",
    "asc_codes = rand.randint(low=65, high=91, size=words_iter[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([85, 78, 66, 87, 67, 73, 71, 84, 77, 65, 67, 71, 74, 81, 65, 82, 87,\n",
       "       86, 82, 75, 66, 79, 70, 85, 83, 73, 66, 90, 72, 67, 67, 67, 77, 90,\n",
       "       88, 69, 80, 78, 67, 69, 67, 87, 78, 80, 86, 83, 78, 71, 89, 80])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a peek at the ascii codes that were generated\n",
    "asc_codes[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['U',\n",
       " 'N',\n",
       " 'B',\n",
       " 'W',\n",
       " 'C',\n",
       " 'I',\n",
       " 'G',\n",
       " 'T',\n",
       " 'M',\n",
       " 'A',\n",
       " 'C',\n",
       " 'G',\n",
       " 'J',\n",
       " 'Q',\n",
       " 'A',\n",
       " 'R',\n",
       " 'W',\n",
       " 'V',\n",
       " 'R',\n",
       " 'K']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f = lambda x: chr(x)\n",
    "#chars = f(asc_codes.tolist())\n",
    "# The above did not work, so we will use the following instead\n",
    "# to convert the ascii codes to characters\n",
    "chars = [chr(x) for x in asc_codes.tolist()]\n",
    "chars[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UNBW',\n",
       " 'CIG',\n",
       " 'TMAC',\n",
       " 'GJQARWVR',\n",
       " 'K',\n",
       " 'BO',\n",
       " 'FUSIBZHCCC',\n",
       " 'MZXEPNCE',\n",
       " 'C',\n",
       " 'W',\n",
       " 'NPV',\n",
       " 'SNGYPO',\n",
       " 'KIZZNITZXM',\n",
       " 'FFXDQYIKVO',\n",
       " 'BWJO',\n",
       " 'F',\n",
       " 'OVPMLWF',\n",
       " 'CEXM',\n",
       " 'SKU',\n",
       " 'YUHI']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking the long list of characters that was generated by our conversion from ascii to char\n",
    "# we use the numpy.split() method in which the 2nd parameter tells us at which index locations\n",
    "# to split the array (this is why ithertools was handy)\n",
    "words = [''.join(x) for x in np.split(chars, words_iter[:-1])]\n",
    "\n",
    "# Let's see the first 20 words we created\n",
    "words[:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14,\n",
       " 15,\n",
       " 30,\n",
       " 43,\n",
       " 62,\n",
       " 70,\n",
       " 86,\n",
       " 94,\n",
       " 99,\n",
       " 107,\n",
       " 125,\n",
       " 136,\n",
       " 141,\n",
       " 160,\n",
       " 173,\n",
       " 188,\n",
       " 207,\n",
       " 212,\n",
       " 225,\n",
       " 230]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# At this point, we have a list of words but we still need to split those words up into sentences (or records)\n",
    "# Once again, we use itertools to accumulate the count so that we can pass this to the numpy.split() method\n",
    "sentences_iter = list(itools.accumulate(sentence_templates))\n",
    "\n",
    "sentences_iter[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[{UNBW, CIG, TMAC, GJQARWVR, K, BO, FUSIBZHCCC, MZXEPNCE, C, W, NPV, SNGYPO, KIZZNITZXM, FFXDQYIKVO}]',\n",
       " '[{BWJO}]',\n",
       " '[{F, OVPMLWF, CEXM, SKU, YUHI, GEXMKJWD, HFF, JYQZNP, R, DULZMLAAPV, HJDV, DDAFCED, XMVJTDDR, APAU, F}]',\n",
       " '[{XLO, RHKZLL, QWQLHE, EZVVCZ, MP, IVWBTMDVJL, AMLBHZT, QVRS, DDUQJU, NTUGP, FWYGBOV, PFQCF, Y}]',\n",
       " '[{UBY, CFIKXQCE, NPZWEGA, BQPZWGBJ, PAIVAZG, GEQZHC, O, VFU, AE, SQHHYL, LUAHATOVVO, PZJCZJITC, BWM, JMUSGIJOD, KGPUAA, S, FXICBFU, IL, N}]',\n",
       " '[{OHOVG, XOVPSV, KSHZYWMM, XULZ, TUKJHCI, QYIPPENLMR, MKAM, SDQIKWE}]',\n",
       " '[{RS, QVQFDCK, ZDE, F, JZRRVIKVYW, COCMZDG, ATDMF, ISQ, NBLOHJ, YMHZLPS, QCOMJTSNEX, UOKL, MYOB, AAUQUQR, UWEX, X}]',\n",
       " '[{YYQDLUUVRO, G, Q, GXUT, JFMF, NJTJ, O, CO}]',\n",
       " '[{LSYXUGDL, BO, OXNQYHSMR, NISJXACWY, NONNXGONX}]',\n",
       " '[{RYGX, SNJ, LWHCWZID, RTYXJIHU, PQNXGEKJ, CDF, JLYGMM, HOAP}]']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we apply the numpy.split method, but this time to a list of words rather than a list of characters\n",
    "\n",
    "# For the source data, if we want the individual words to be wrapped in quotes, use:\n",
    "#sentences = ['[{\"' + str('\", \"'. join(x)) + '\"}]' for x in np.split(words, sentences_iter[:-1])]\n",
    "# For the source data, if we want no quotes around the individual words (as originally presented by my friend), use:\n",
    "sentences = ['[{' + str(', '. join(x)) + '}]' for x in np.split(words, sentences_iter[:-1])]\n",
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JSON_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{UNBW, CIG, TMAC, GJQARWVR, K, BO, FUSIBZHCCC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{BWJO}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{F, OVPMLWF, CEXM, SKU, YUHI, GEXMKJWD, HFF, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{XLO, RHKZLL, QWQLHE, EZVVCZ, MP, IVWBTMDVJL,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{UBY, CFIKXQCE, NPZWEGA, BQPZWGBJ, PAIVAZG, G...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          JSON_words\n",
       "0  [{UNBW, CIG, TMAC, GJQARWVR, K, BO, FUSIBZHCCC...\n",
       "1                                           [{BWJO}]\n",
       "2  [{F, OVPMLWF, CEXM, SKU, YUHI, GEXMKJWD, HFF, ...\n",
       "3  [{XLO, RHKZLL, QWQLHE, EZVVCZ, MP, IVWBTMDVJL,...\n",
       "4  [{UBY, CFIKXQCE, NPZWEGA, BQPZWGBJ, PAIVAZG, G..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we have a list of \"sentences\", we can push them into a Pandas data frame\n",
    "df_sentences = pd.DataFrame(sentences, columns=[\"JSON_words\"])\n",
    "df_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now, we can save the data frame so that\n",
    "# we can repeatedly test against the same data using different methods\n",
    "df_sentences.to_csv(\"create_random_words_test_data.csv\", sep=\"|\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JSON_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{UNBW, CIG, TMAC, GJQARWVR, K, BO, FUSIBZHCCC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{BWJO}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{F, OVPMLWF, CEXM, SKU, YUHI, GEXMKJWD, HFF, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{XLO, RHKZLL, QWQLHE, EZVVCZ, MP, IVWBTMDVJL,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{UBY, CFIKXQCE, NPZWEGA, BQPZWGBJ, PAIVAZG, G...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          JSON_words\n",
       "0  [{UNBW, CIG, TMAC, GJQARWVR, K, BO, FUSIBZHCCC...\n",
       "1                                           [{BWJO}]\n",
       "2  [{F, OVPMLWF, CEXM, SKU, YUHI, GEXMKJWD, HFF, ...\n",
       "3  [{XLO, RHKZLL, QWQLHE, EZVVCZ, MP, IVWBTMDVJL,...\n",
       "4  [{UBY, CFIKXQCE, NPZWEGA, BQPZWGBJ, PAIVAZG, G..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data back from the file we saved, and re-display the head\n",
    "df_map = pd.read_csv(\"create_random_words_test_data.csv\", sep=\"|\")\n",
    "df_map.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.29 s ± 29.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "# Use numpy.Series.map to transform the data\n",
    "\n",
    "# If the source data does not contain words wrapped with double quotes, use:\n",
    "df_map[\"JSON_words_transformed\"] = df_map[\"JSON_words\"].map(lambda x: ['\"' + y + '\"' for y in re.split(\"[, ]+\", x[2:-2])])\n",
    "# If the source data already contains words wrapped with double quotes, use:\n",
    "#df_map[\"JSON_words\"] = [re.sub(\"[{}]\", \"\", str(x)) for x in df_map[\"JSON_words\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JSON_words</th>\n",
       "      <th>JSON_words_transformed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{UNBW, CIG, TMAC, GJQARWVR, K, BO, FUSIBZHCCC...</td>\n",
       "      <td>[\"UNBW\", \"CIG\", \"TMAC\", \"GJQARWVR\", \"K\", \"BO\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{BWJO}]</td>\n",
       "      <td>[\"BWJO\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{F, OVPMLWF, CEXM, SKU, YUHI, GEXMKJWD, HFF, ...</td>\n",
       "      <td>[\"F\", \"OVPMLWF\", \"CEXM\", \"SKU\", \"YUHI\", \"GEXMK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{XLO, RHKZLL, QWQLHE, EZVVCZ, MP, IVWBTMDVJL,...</td>\n",
       "      <td>[\"XLO\", \"RHKZLL\", \"QWQLHE\", \"EZVVCZ\", \"MP\", \"I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{UBY, CFIKXQCE, NPZWEGA, BQPZWGBJ, PAIVAZG, G...</td>\n",
       "      <td>[\"UBY\", \"CFIKXQCE\", \"NPZWEGA\", \"BQPZWGBJ\", \"PA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          JSON_words  \\\n",
       "0  [{UNBW, CIG, TMAC, GJQARWVR, K, BO, FUSIBZHCCC...   \n",
       "1                                           [{BWJO}]   \n",
       "2  [{F, OVPMLWF, CEXM, SKU, YUHI, GEXMKJWD, HFF, ...   \n",
       "3  [{XLO, RHKZLL, QWQLHE, EZVVCZ, MP, IVWBTMDVJL,...   \n",
       "4  [{UBY, CFIKXQCE, NPZWEGA, BQPZWGBJ, PAIVAZG, G...   \n",
       "\n",
       "                              JSON_words_transformed  \n",
       "0  [\"UNBW\", \"CIG\", \"TMAC\", \"GJQARWVR\", \"K\", \"BO\",...  \n",
       "1                                           [\"BWJO\"]  \n",
       "2  [\"F\", \"OVPMLWF\", \"CEXM\", \"SKU\", \"YUHI\", \"GEXMK...  \n",
       "3  [\"XLO\", \"RHKZLL\", \"QWQLHE\", \"EZVVCZ\", \"MP\", \"I...  \n",
       "4  [\"UBY\", \"CFIKXQCE\", \"NPZWEGA\", \"BQPZWGBJ\", \"PA...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_map.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JSON_words</th>\n",
       "      <th>JSON_words_transformed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>[{NHUKCSM, DHV, WLMC, DSUC, LOTD, M, BTY, GSQE...</td>\n",
       "      <td>[\"NHUKCSM\", \"DHV\", \"WLMC\", \"DSUC\", \"LOTD\", \"M\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>[{SDYSTW, DPSRCF, AATRTNQAX, YNHABVAHER, F, HS...</td>\n",
       "      <td>[\"SDYSTW\", \"DPSRCF\", \"AATRTNQAX\", \"YNHABVAHER\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>[{WCBETOSGM, SWIJJZLFJ}]</td>\n",
       "      <td>[\"WCBETOSGM\", \"SWIJJZLFJ\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>[{BLAODGAREM, XS, ISENYAWZVF, EKEN, BFER, WSTA...</td>\n",
       "      <td>[\"BLAODGAREM\", \"XS\", \"ISENYAWZVF\", \"EKEN\", \"BF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>[{JJDISUNY, UQQKEDXKOI, BKMNWW, GNAG, ACOCRMX,...</td>\n",
       "      <td>[\"JJDISUNY\", \"UQQKEDXKOI\", \"BKMNWW\", \"GNAG\", \"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               JSON_words  \\\n",
       "999995  [{NHUKCSM, DHV, WLMC, DSUC, LOTD, M, BTY, GSQE...   \n",
       "999996  [{SDYSTW, DPSRCF, AATRTNQAX, YNHABVAHER, F, HS...   \n",
       "999997                           [{WCBETOSGM, SWIJJZLFJ}]   \n",
       "999998  [{BLAODGAREM, XS, ISENYAWZVF, EKEN, BFER, WSTA...   \n",
       "999999  [{JJDISUNY, UQQKEDXKOI, BKMNWW, GNAG, ACOCRMX,...   \n",
       "\n",
       "                                   JSON_words_transformed  \n",
       "999995  [\"NHUKCSM\", \"DHV\", \"WLMC\", \"DSUC\", \"LOTD\", \"M\"...  \n",
       "999996  [\"SDYSTW\", \"DPSRCF\", \"AATRTNQAX\", \"YNHABVAHER\"...  \n",
       "999997                         [\"WCBETOSGM\", \"SWIJJZLFJ\"]  \n",
       "999998  [\"BLAODGAREM\", \"XS\", \"ISENYAWZVF\", \"EKEN\", \"BF...  \n",
       "999999  [\"JJDISUNY\", \"UQQKEDXKOI\", \"BKMNWW\", \"GNAG\", \"...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_map.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JSON_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{UNBW, CIG, TMAC, GJQARWVR, K, BO, FUSIBZHCCC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{BWJO}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{F, OVPMLWF, CEXM, SKU, YUHI, GEXMKJWD, HFF, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{XLO, RHKZLL, QWQLHE, EZVVCZ, MP, IVWBTMDVJL,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{UBY, CFIKXQCE, NPZWEGA, BQPZWGBJ, PAIVAZG, G...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          JSON_words\n",
       "0  [{UNBW, CIG, TMAC, GJQARWVR, K, BO, FUSIBZHCCC...\n",
       "1                                           [{BWJO}]\n",
       "2  [{F, OVPMLWF, CEXM, SKU, YUHI, GEXMKJWD, HFF, ...\n",
       "3  [{XLO, RHKZLL, QWQLHE, EZVVCZ, MP, IVWBTMDVJL,...\n",
       "4  [{UBY, CFIKXQCE, NPZWEGA, BQPZWGBJ, PAIVAZG, G..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_apply = pd.read_csv(\"create_random_words_test_data.csv\", sep=\"|\")\n",
    "df_apply.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.31 s ± 46.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "# Use numpy.Series.apply to transform the data\n",
    "\n",
    "df_apply[\"JSON_words_transformed\"] = df_apply[\"JSON_words\"].apply(lambda x: ['\"' + y + '\"' for y in re.split(\"[, ]+\", x[2:-2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JSON_words</th>\n",
       "      <th>JSON_words_transformed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{UNBW, CIG, TMAC, GJQARWVR, K, BO, FUSIBZHCCC...</td>\n",
       "      <td>[\"UNBW\", \"CIG\", \"TMAC\", \"GJQARWVR\", \"K\", \"BO\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{BWJO}]</td>\n",
       "      <td>[\"BWJO\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{F, OVPMLWF, CEXM, SKU, YUHI, GEXMKJWD, HFF, ...</td>\n",
       "      <td>[\"F\", \"OVPMLWF\", \"CEXM\", \"SKU\", \"YUHI\", \"GEXMK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{XLO, RHKZLL, QWQLHE, EZVVCZ, MP, IVWBTMDVJL,...</td>\n",
       "      <td>[\"XLO\", \"RHKZLL\", \"QWQLHE\", \"EZVVCZ\", \"MP\", \"I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{UBY, CFIKXQCE, NPZWEGA, BQPZWGBJ, PAIVAZG, G...</td>\n",
       "      <td>[\"UBY\", \"CFIKXQCE\", \"NPZWEGA\", \"BQPZWGBJ\", \"PA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          JSON_words  \\\n",
       "0  [{UNBW, CIG, TMAC, GJQARWVR, K, BO, FUSIBZHCCC...   \n",
       "1                                           [{BWJO}]   \n",
       "2  [{F, OVPMLWF, CEXM, SKU, YUHI, GEXMKJWD, HFF, ...   \n",
       "3  [{XLO, RHKZLL, QWQLHE, EZVVCZ, MP, IVWBTMDVJL,...   \n",
       "4  [{UBY, CFIKXQCE, NPZWEGA, BQPZWGBJ, PAIVAZG, G...   \n",
       "\n",
       "                              JSON_words_transformed  \n",
       "0  [\"UNBW\", \"CIG\", \"TMAC\", \"GJQARWVR\", \"K\", \"BO\",...  \n",
       "1                                           [\"BWJO\"]  \n",
       "2  [\"F\", \"OVPMLWF\", \"CEXM\", \"SKU\", \"YUHI\", \"GEXMK...  \n",
       "3  [\"XLO\", \"RHKZLL\", \"QWQLHE\", \"EZVVCZ\", \"MP\", \"I...  \n",
       "4  [\"UBY\", \"CFIKXQCE\", \"NPZWEGA\", \"BQPZWGBJ\", \"PA...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_apply.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JSON_words</th>\n",
       "      <th>JSON_words_transformed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>[{NHUKCSM, DHV, WLMC, DSUC, LOTD, M, BTY, GSQE...</td>\n",
       "      <td>[\"NHUKCSM\", \"DHV\", \"WLMC\", \"DSUC\", \"LOTD\", \"M\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>[{SDYSTW, DPSRCF, AATRTNQAX, YNHABVAHER, F, HS...</td>\n",
       "      <td>[\"SDYSTW\", \"DPSRCF\", \"AATRTNQAX\", \"YNHABVAHER\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>[{WCBETOSGM, SWIJJZLFJ}]</td>\n",
       "      <td>[\"WCBETOSGM\", \"SWIJJZLFJ\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>[{BLAODGAREM, XS, ISENYAWZVF, EKEN, BFER, WSTA...</td>\n",
       "      <td>[\"BLAODGAREM\", \"XS\", \"ISENYAWZVF\", \"EKEN\", \"BF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>[{JJDISUNY, UQQKEDXKOI, BKMNWW, GNAG, ACOCRMX,...</td>\n",
       "      <td>[\"JJDISUNY\", \"UQQKEDXKOI\", \"BKMNWW\", \"GNAG\", \"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               JSON_words  \\\n",
       "999995  [{NHUKCSM, DHV, WLMC, DSUC, LOTD, M, BTY, GSQE...   \n",
       "999996  [{SDYSTW, DPSRCF, AATRTNQAX, YNHABVAHER, F, HS...   \n",
       "999997                           [{WCBETOSGM, SWIJJZLFJ}]   \n",
       "999998  [{BLAODGAREM, XS, ISENYAWZVF, EKEN, BFER, WSTA...   \n",
       "999999  [{JJDISUNY, UQQKEDXKOI, BKMNWW, GNAG, ACOCRMX,...   \n",
       "\n",
       "                                   JSON_words_transformed  \n",
       "999995  [\"NHUKCSM\", \"DHV\", \"WLMC\", \"DSUC\", \"LOTD\", \"M\"...  \n",
       "999996  [\"SDYSTW\", \"DPSRCF\", \"AATRTNQAX\", \"YNHABVAHER\"...  \n",
       "999997                         [\"WCBETOSGM\", \"SWIJJZLFJ\"]  \n",
       "999998  [\"BLAODGAREM\", \"XS\", \"ISENYAWZVF\", \"EKEN\", \"BF...  \n",
       "999999  [\"JJDISUNY\", \"UQQKEDXKOI\", \"BKMNWW\", \"GNAG\", \"...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_apply.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JSON_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{UNBW, CIG, TMAC, GJQARWVR, K, BO, FUSIBZHCCC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{BWJO}]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{F, OVPMLWF, CEXM, SKU, YUHI, GEXMKJWD, HFF, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{XLO, RHKZLL, QWQLHE, EZVVCZ, MP, IVWBTMDVJL,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{UBY, CFIKXQCE, NPZWEGA, BQPZWGBJ, PAIVAZG, G...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          JSON_words\n",
       "0  [{UNBW, CIG, TMAC, GJQARWVR, K, BO, FUSIBZHCCC...\n",
       "1                                           [{BWJO}]\n",
       "2  [{F, OVPMLWF, CEXM, SKU, YUHI, GEXMKJWD, HFF, ...\n",
       "3  [{XLO, RHKZLL, QWQLHE, EZVVCZ, MP, IVWBTMDVJL,...\n",
       "4  [{UBY, CFIKXQCE, NPZWEGA, BQPZWGBJ, PAIVAZG, G..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What about using str.replace or re.sub?\n",
    "\n",
    "df_replace = pd.read_csv(\"create_random_words_test_data.csv\", sep=\"|\")\n",
    "df_replace.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13 s ± 4.75 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "# If we are certain that the data is in a specific format for which we know\n",
    "# we can perform regex substitutions, or string replacements, we may get better performance\n",
    "\n",
    "df_replace[\"JSON_words_transformed\"] = [str(x)\n",
    "                                        .replace(', ', '\", \"')\n",
    "                                        .replace('[{', '[\"')\n",
    "                                        .replace('}]', '\"]')\n",
    "                                        for x in df_replace[\"JSON_words\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JSON_words</th>\n",
       "      <th>JSON_words_transformed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{UNBW, CIG, TMAC, GJQARWVR, K, BO, FUSIBZHCCC...</td>\n",
       "      <td>[\"UNBW\", \"CIG\", \"TMAC\", \"GJQARWVR\", \"K\", \"BO\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[{BWJO}]</td>\n",
       "      <td>[\"BWJO\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[{F, OVPMLWF, CEXM, SKU, YUHI, GEXMKJWD, HFF, ...</td>\n",
       "      <td>[\"F\", \"OVPMLWF\", \"CEXM\", \"SKU\", \"YUHI\", \"GEXMK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[{XLO, RHKZLL, QWQLHE, EZVVCZ, MP, IVWBTMDVJL,...</td>\n",
       "      <td>[\"XLO\", \"RHKZLL\", \"QWQLHE\", \"EZVVCZ\", \"MP\", \"I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[{UBY, CFIKXQCE, NPZWEGA, BQPZWGBJ, PAIVAZG, G...</td>\n",
       "      <td>[\"UBY\", \"CFIKXQCE\", \"NPZWEGA\", \"BQPZWGBJ\", \"PA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          JSON_words  \\\n",
       "0  [{UNBW, CIG, TMAC, GJQARWVR, K, BO, FUSIBZHCCC...   \n",
       "1                                           [{BWJO}]   \n",
       "2  [{F, OVPMLWF, CEXM, SKU, YUHI, GEXMKJWD, HFF, ...   \n",
       "3  [{XLO, RHKZLL, QWQLHE, EZVVCZ, MP, IVWBTMDVJL,...   \n",
       "4  [{UBY, CFIKXQCE, NPZWEGA, BQPZWGBJ, PAIVAZG, G...   \n",
       "\n",
       "                              JSON_words_transformed  \n",
       "0  [\"UNBW\", \"CIG\", \"TMAC\", \"GJQARWVR\", \"K\", \"BO\",...  \n",
       "1                                           [\"BWJO\"]  \n",
       "2  [\"F\", \"OVPMLWF\", \"CEXM\", \"SKU\", \"YUHI\", \"GEXMK...  \n",
       "3  [\"XLO\", \"RHKZLL\", \"QWQLHE\", \"EZVVCZ\", \"MP\", \"I...  \n",
       "4  [\"UBY\", \"CFIKXQCE\", \"NPZWEGA\", \"BQPZWGBJ\", \"PA...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_replace.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JSON_words</th>\n",
       "      <th>JSON_words_transformed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>999995</th>\n",
       "      <td>[{NHUKCSM, DHV, WLMC, DSUC, LOTD, M, BTY, GSQE...</td>\n",
       "      <td>[\"NHUKCSM\", \"DHV\", \"WLMC\", \"DSUC\", \"LOTD\", \"M\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999996</th>\n",
       "      <td>[{SDYSTW, DPSRCF, AATRTNQAX, YNHABVAHER, F, HS...</td>\n",
       "      <td>[\"SDYSTW\", \"DPSRCF\", \"AATRTNQAX\", \"YNHABVAHER\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999997</th>\n",
       "      <td>[{WCBETOSGM, SWIJJZLFJ}]</td>\n",
       "      <td>[\"WCBETOSGM\", \"SWIJJZLFJ\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999998</th>\n",
       "      <td>[{BLAODGAREM, XS, ISENYAWZVF, EKEN, BFER, WSTA...</td>\n",
       "      <td>[\"BLAODGAREM\", \"XS\", \"ISENYAWZVF\", \"EKEN\", \"BF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999999</th>\n",
       "      <td>[{JJDISUNY, UQQKEDXKOI, BKMNWW, GNAG, ACOCRMX,...</td>\n",
       "      <td>[\"JJDISUNY\", \"UQQKEDXKOI\", \"BKMNWW\", \"GNAG\", \"...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               JSON_words  \\\n",
       "999995  [{NHUKCSM, DHV, WLMC, DSUC, LOTD, M, BTY, GSQE...   \n",
       "999996  [{SDYSTW, DPSRCF, AATRTNQAX, YNHABVAHER, F, HS...   \n",
       "999997                           [{WCBETOSGM, SWIJJZLFJ}]   \n",
       "999998  [{BLAODGAREM, XS, ISENYAWZVF, EKEN, BFER, WSTA...   \n",
       "999999  [{JJDISUNY, UQQKEDXKOI, BKMNWW, GNAG, ACOCRMX,...   \n",
       "\n",
       "                                   JSON_words_transformed  \n",
       "999995  [\"NHUKCSM\", \"DHV\", \"WLMC\", \"DSUC\", \"LOTD\", \"M\"...  \n",
       "999996  [\"SDYSTW\", \"DPSRCF\", \"AATRTNQAX\", \"YNHABVAHER\"...  \n",
       "999997                         [\"WCBETOSGM\", \"SWIJJZLFJ\"]  \n",
       "999998  [\"BLAODGAREM\", \"XS\", \"ISENYAWZVF\", \"EKEN\", \"BF...  \n",
       "999999  [\"JJDISUNY\", \"UQQKEDXKOI\", \"BKMNWW\", \"GNAG\", \"...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_replace.tail()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f8b40d688a12481f01eadf7380c47edd8a49484a47dba3db091451640e880c68"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
